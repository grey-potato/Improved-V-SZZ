#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
LLM BFCéªŒè¯æ¨¡å—
ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹éªŒè¯å’Œç²¾åŒ–BFCè¯†åˆ«ç»“æœ
"""

import json
import os
from typing import Dict, List
from git import Repo


class LLMBFCVerifier:
    """
    ä½¿ç”¨LLMéªŒè¯BFCçš„ç±»
    é˜¶æ®µ1: éªŒè¯å€™é€‰BFCæ˜¯å¦çœŸçš„æ˜¯å®‰å…¨ä¿®å¤
    """
    
    def __init__(self, repo_path: str, llm_client=None):
        """
        åˆå§‹åŒ–LLMéªŒè¯å™¨
        
        Args:
            repo_path: Gitä»“åº“è·¯å¾„
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆå¦‚OpenAI, Anthropicç­‰ï¼‰
        """
        self.repo_path = repo_path
        self.repo = Repo(repo_path)
        self.llm = llm_client
    
    def verify_bfc(self, candidate: Dict, include_diff: bool = True) -> Dict:
        """
        éªŒè¯å•ä¸ªBFCå€™é€‰
        
        Args:
            candidate: å€™é€‰BFCä¿¡æ¯
            include_diff: æ˜¯å¦åœ¨promptä¸­åŒ…å«å®Œæ•´diff
            
        Returns:
            éªŒè¯ç»“æœ
        """
        commit = self.repo.commit(candidate['commit_hash'])
        
        # æ„å»ºprompt
        prompt = self._build_verification_prompt(candidate, commit, include_diff)
        
        # è°ƒç”¨LLM
        if self.llm is None:
            # å¦‚æœæ²¡æœ‰LLMå®¢æˆ·ç«¯ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ
            print(f"âš ï¸ è­¦å‘Š: æœªé…ç½®LLMå®¢æˆ·ç«¯ï¼Œè¿”å›åŸºäºè§„åˆ™çš„ç»“æœ")
            return self._rule_based_verification(candidate)
        
        try:
            response = self._call_llm(prompt)
            result = self._parse_llm_response(response)
            
            # æ·»åŠ é¢å¤–ä¿¡æ¯
            result['commit_hash'] = candidate['commit_hash']
            result['original_score'] = candidate['total_score']
            
            return result
        
        except Exception as e:
            print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            return self._rule_based_verification(candidate)
    
    def verify_batch(self, candidates: List[Dict], 
                    max_verify: int = 20) -> List[Dict]:
        """
        æ‰¹é‡éªŒè¯BFCå€™é€‰
        
        Args:
            candidates: å€™é€‰åˆ—è¡¨
            max_verify: æœ€å¤šéªŒè¯æ•°é‡ï¼ˆæ§åˆ¶æˆæœ¬ï¼‰
        """
        print(f"\nğŸ¤– å¼€å§‹LLMéªŒè¯ï¼ˆæœ€å¤š {max_verify} ä¸ªï¼‰...")
        
        verified = []
        
        # ä¼˜å…ˆéªŒè¯é«˜åˆ†å€™é€‰
        candidates_sorted = sorted(candidates, 
                                   key=lambda x: x['total_score'], 
                                   reverse=True)
        
        for i, candidate in enumerate(candidates_sorted[:max_verify], 1):
            print(f"\nå¤„ç† {i}/{min(max_verify, len(candidates))}: {candidate['short_hash']}")
            
            result = self.verify_bfc(candidate)
            verified.append(result)
            
            # æ˜¾ç¤ºç»“æœ
            if result['is_valid_bfc']:
                print(f"  âœ“ éªŒè¯é€šè¿‡ (ç½®ä¿¡åº¦: {result['confidence']:.2f})")
                print(f"    ç±»å‹: {result.get('vulnerability_type', 'Unknown')}")
            else:
                print(f"  âœ— ä¸æ˜¯BFC (ç½®ä¿¡åº¦: {result['confidence']:.2f})")
        
        # è¿‡æ»¤å‡ºéªŒè¯é€šè¿‡çš„
        valid_bfcs = [r for r in verified 
                     if r['is_valid_bfc'] and r['confidence'] >= 0.7]
        
        print(f"\nâœ“ éªŒè¯å®Œæˆ: {len(valid_bfcs)}/{len(verified)} ä¸ªé€šè¿‡éªŒè¯")
        
        return verified
    
    def _build_verification_prompt(self, candidate: Dict, 
                                   commit, include_diff: bool) -> str:
        """æ„å»ºLLMéªŒè¯prompt"""
        
        # è·å–diff
        diff_text = ""
        if include_diff and len(commit.parents) > 0:
            try:
                diffs = commit.diff(commit.parents[0], create_patch=True)
                diff_lines = []
                for diff in diffs[:5]:  # åªå–å‰5ä¸ªæ–‡ä»¶
                    if diff.diff:
                        try:
                            diff_lines.append(diff.diff.decode('utf-8', errors='ignore'))
                        except:
                            pass
                diff_text = '\n'.join(diff_lines[:2000])  # é™åˆ¶é•¿åº¦
            except:
                diff_text = "[æ— æ³•è·å–diff]"
        
        # è·å–ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨
        files = list(commit.stats.files.keys())
        files_str = '\n'.join(f"  - {f}" for f in files[:10])
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹Gitæäº¤ï¼Œåˆ¤æ–­å®ƒæ˜¯å¦æ˜¯å®‰å…¨æ¼æ´ä¿®å¤æäº¤ï¼ˆBFC - Bug Fixing Commitï¼‰ã€‚

# æäº¤ä¿¡æ¯
- Commit Hash: {candidate['commit_hash']}
- æ—¥æœŸ: {candidate['date']}
- ä½œè€…: {candidate['author']}
- æäº¤æ¶ˆæ¯:
```
{candidate['message']}
```

# ä¿®æ”¹ç»Ÿè®¡
- ä¿®æ”¹æ–‡ä»¶æ•°: {candidate['files_changed']}
- æ–°å¢è¡Œæ•°: {candidate['insertions']}
- åˆ é™¤è¡Œæ•°: {candidate['deletions']}

# ä¿®æ”¹çš„æ–‡ä»¶
{files_str}

# ä»£ç å˜æ›´
```diff
{diff_text}
```

# åˆæ­¥åˆ†æ
- æ¶ˆæ¯åˆ†æ: {candidate.get('message_reason', 'æ— ')}
- æ£€æµ‹åˆ°çš„æ¨¡å¼: {', '.join(candidate.get('code_patterns', [])) or 'æ— '}

---

è¯·æ·±å…¥åˆ†æå¹¶å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

1. **è¿™æ˜¯å®‰å…¨æ¼æ´ä¿®å¤å—ï¼Ÿ** 
   - è€ƒè™‘ï¼šæ˜¯å¦ä¿®å¤äº†å…·ä½“çš„å®‰å…¨é—®é¢˜ï¼Ÿ
   - è€ƒè™‘ï¼šæ˜¯å¦åªæ˜¯ä¸€èˆ¬æ€§çš„ä»£ç æ”¹è¿›ï¼Ÿ
   - è€ƒè™‘ï¼šæ˜¯å¦æ˜¯é‡æ„æˆ–åŠŸèƒ½æ·»åŠ ï¼Ÿ

2. **å¦‚æœæ˜¯å®‰å…¨ä¿®å¤ï¼Œæ¼æ´ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ**
   - SQLæ³¨å…¥ã€XSSã€CSRFã€è®¤è¯é—®é¢˜ã€æƒé™æå‡ç­‰
   - å…·ä½“çš„CWEç¼–å·ï¼ˆå¦‚æœèƒ½è¯†åˆ«ï¼‰

3. **ç½®ä¿¡åº¦å¦‚ä½•ï¼Ÿ** (0.0-1.0)
   - è€ƒè™‘ï¼šè¯æ®æ˜¯å¦å……åˆ†ï¼Ÿ
   - è€ƒè™‘ï¼šæ˜¯å¦æœ‰æ¨¡ç³Šä¸æ¸…çš„åœ°æ–¹ï¼Ÿ

4. **æ ¸å¿ƒä¿®å¤æ˜¯åœ¨å“ªäº›æ–‡ä»¶ï¼Ÿ**
   - åŒºåˆ†ï¼šæ ¸å¿ƒå®‰å…¨ä¿®å¤ vs æµ‹è¯•æ–‡ä»¶ vs æ–‡æ¡£æ›´æ–°

5. **ä¿®å¤çš„æ˜¯ä»€ä¹ˆå®‰å…¨é—®é¢˜ï¼Ÿ**
   - ç”¨1-2å¥è¯æè¿°æ¼æ´æœºåˆ¶

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
```json
{{
    "is_valid_bfc": trueæˆ–false,
    "confidence": 0.0åˆ°1.0ä¹‹é—´çš„æ•°å­—,
    "vulnerability_type": "æ¼æ´ç±»å‹ï¼ˆå¦‚SQL Injectionï¼‰",
    "cwe_id": "CWEç¼–å·ï¼ˆå¦‚CWE-89ï¼‰æˆ–null",
    "severity": "High/Medium/Lowæˆ–null",
    "core_fix_files": ["æ ¸å¿ƒä¿®å¤æ–‡ä»¶1", "æ ¸å¿ƒä¿®å¤æ–‡ä»¶2"],
    "excluded_files": ["æµ‹è¯•æˆ–æ–‡æ¡£æ–‡ä»¶"],
    "vulnerability_description": "ç®€çŸ­æè¿°æ¼æ´",
    "fix_description": "ç®€çŸ­æè¿°ä¿®å¤æ–¹å¼",
    "reasoning": "ä½ çš„åˆ†ææ¨ç†è¿‡ç¨‹",
    "evidence": ["è¯æ®1", "è¯æ®2"]
}}
```

åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        
        return prompt
    
    def _call_llm(self, prompt: str) -> str:
        """
        è°ƒç”¨LLM API
        éœ€è¦æ ¹æ®å…·ä½“çš„LLMå®¢æˆ·ç«¯å®ç°
        """
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…ä½¿ç”¨çš„LLMå®ç°
        # ç¤ºä¾‹ï¼šOpenAI
        if hasattr(self.llm, 'chat') and hasattr(self.llm.chat, 'completions'):
            response = self.llm.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®‰å…¨æ¼æ´åˆ†æä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            return response.choices[0].message.content
        
        # ç¤ºä¾‹ï¼šAnthropic Claude
        elif hasattr(self.llm, 'messages') and hasattr(self.llm.messages, 'create'):
            response = self.llm.messages.create(
                model="claude-3-opus-20240229",
                max_tokens=2000,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return response.content[0].text
        
        else:
            raise ValueError("ä¸æ”¯æŒçš„LLMå®¢æˆ·ç«¯ç±»å‹")
    
    def _parse_llm_response(self, response: str) -> Dict:
        """è§£æLLMè¿”å›çš„JSON"""
        try:
            # å°è¯•ç›´æ¥è§£æ
            return json.loads(response)
        except json.JSONDecodeError:
            # å°è¯•æå–JSONå—
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            
            # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª{å’Œæœ€åä¸€ä¸ª}
            start = response.find('{')
            end = response.rfind('}')
            if start != -1 and end != -1:
                return json.loads(response[start:end+1])
            
            raise ValueError("æ— æ³•è§£æLLMå“åº”ä¸ºJSON")
    
    def _rule_based_verification(self, candidate: Dict) -> Dict:
        """
        åŸºäºè§„åˆ™çš„éªŒè¯ï¼ˆå½“æ²¡æœ‰LLMæ—¶çš„åå¤‡æ–¹æ¡ˆï¼‰
        """
        score = candidate['total_score']
        
        # ç®€å•çš„è§„åˆ™
        if score >= 20:
            confidence = 0.8
            is_valid = True
        elif score >= 10:
            confidence = 0.6
            is_valid = True
        else:
            confidence = 0.4
            is_valid = False
        
        return {
            'is_valid_bfc': is_valid,
            'confidence': confidence,
            'vulnerability_type': 'Unknown',
            'cwe_id': None,
            'severity': None,
            'core_fix_files': candidate.get('modified_files', []),
            'excluded_files': [],
            'vulnerability_description': 'åŸºäºè§„åˆ™çš„åˆ¤æ–­',
            'fix_description': 'åŸºäºè§„åˆ™çš„åˆ¤æ–­',
            'reasoning': f'åŸºäºå…³é”®è¯å’Œæ¨¡å¼çš„è§„åˆ™åˆ¤æ–­ï¼Œæ€»åˆ†ï¼š{score}',
            'evidence': candidate.get('code_patterns', []),
            'commit_hash': candidate['commit_hash'],
            'original_score': score
        }
    
    def export_verified_bfcs(self, verified: List[Dict], 
                            output_file: str = 'verified_bfcs.json'):
        """å¯¼å‡ºéªŒè¯ç»“æœ"""
        output_path = os.path.join(os.path.dirname(self.repo_path), output_file)
        
        # åªå¯¼å‡ºéªŒè¯é€šè¿‡çš„
        valid_bfcs = [v for v in verified 
                     if v['is_valid_bfc'] and v['confidence'] >= 0.7]
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(valid_bfcs, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ éªŒè¯é€šè¿‡çš„BFCå·²å¯¼å‡ºåˆ°: {output_path}")
        print(f"  å…± {len(valid_bfcs)} ä¸ªBFC")
        
        return output_path
    
    def print_verification_summary(self, verified: List[Dict]):
        """æ‰“å°éªŒè¯æ‘˜è¦"""
        print("\n" + "=" * 80)
        print("ğŸ“Š BFCéªŒè¯ç»“æœæ‘˜è¦")
        print("=" * 80)
        
        valid = [v for v in verified if v['is_valid_bfc']]
        high_conf = [v for v in valid if v['confidence'] >= 0.8]
        medium_conf = [v for v in valid if 0.6 <= v['confidence'] < 0.8]
        
        print(f"\næ€»è®¡éªŒè¯: {len(verified)} ä¸ª")
        print(f"  âœ“ éªŒè¯é€šè¿‡: {len(valid)} ä¸ª")
        print(f"    - é«˜ç½®ä¿¡åº¦ (>=0.8): {len(high_conf)} ä¸ª")
        print(f"    - ä¸­ç½®ä¿¡åº¦ (0.6-0.8): {len(medium_conf)} ä¸ª")
        print(f"  âœ— æœªé€šè¿‡: {len(verified) - len(valid)} ä¸ª")
        
        # æ¼æ´ç±»å‹ç»Ÿè®¡
        if valid:
            print("\næ¼æ´ç±»å‹åˆ†å¸ƒ:")
            vuln_types = {}
            for v in valid:
                vtype = v.get('vulnerability_type', 'Unknown')
                vuln_types[vtype] = vuln_types.get(vtype, 0) + 1
            
            for vtype, count in sorted(vuln_types.items(), 
                                      key=lambda x: x[1], reverse=True):
                print(f"  - {vtype}: {count}")
        
        print()


def demo_without_llm():
    """æ¼”ç¤ºä¸ä½¿ç”¨çœŸå®LLMçš„æƒ…å†µ"""
    print("æ¼”ç¤ºæ¨¡å¼ï¼šä¸ä½¿ç”¨çœŸå®LLMï¼ŒåŸºäºè§„åˆ™éªŒè¯")
    print("å¦‚éœ€ä½¿ç”¨çœŸå®LLMï¼Œè¯·é…ç½®LLMå®¢æˆ·ç«¯")


if __name__ == '__main__':
    demo_without_llm()
